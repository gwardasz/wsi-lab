{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Zadanie 7 (7 pkt)\n",
        "Celem zadania jest zaimplementowanie dwóch wersji naiwnego klasyfikatora Bayesa.\n",
        "* W pierwszej wersji należy dokonać dyskretyzacji danych - przedział wartości każdego atrybutu dzielimy na cztery równe przedziały i każdej ciągłej wartości atrybutu przypisujemy wartość dyskretną wynikająca z przynależności do danego przedziału.\n",
        "* W drugiej wersji wartości likelihood wyliczamy z rozkładów normalnych o średnich i odchyleniach standardowych wynikających z wartości atrybutów.\n",
        "Trening i test należy przeprowadzić dla zbioru Iris, tak jak w przypadku zadania z drzewem klasyfikacyjnym. Proszę przeprowadzić eksperymenty najpierw dla DOKŁADNIE takiego podziału zbioru testowego i treningowego jak umieszczony poniżej. W dalszej części należy przeprowadzić analizę działania klasyfikatorów dla różnych wartości parametrów. Proszę korzystać z przygotowanego szkieletu programu, oczywiście można go modyfikować według potrzeb. Wszelkie elementy szkieletu zostaną wyjaśnione na zajęciach.\n",
        "\n",
        "* Dyskretyzacja danych - **0.5 pkt**\n",
        "* Implementacja funkcji rozkładu normalnego o zadanej średniej i odchyleniu standardowym. - **0.5 pkt**\n",
        "* Implementacja naiwnego klasyfikatora Bayesa dla danych dyskretnych. - **2.0 pkt**\n",
        "* Implementacja naiwnego klasyfikatora Bayesa dla danych ciągłych. - **2.5 pkt**\n",
        "* Przeprowadzenie eksperymentów, wnioski i sposób ich prezentacji. - **1.5 pkt**"
      ],
      "metadata": {
        "id": "cpar5LziY_-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)"
      ],
      "outputs": [],
      "execution_count": 108,
      "metadata": {
        "id": "XNc-O3npA-J9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_discretization(data, number_of_discrete_values):\n",
        "    for column_index in range(data.shape[-1]):\n",
        "        max_column_value = np.max(data[:,column_index])\n",
        "        min_column_value = np.min(data[:,column_index])\n",
        "        disrete_range = (max_column_value-min_column_value) * 1/number_of_discrete_values\n",
        "        discrete_boundaries = [min_column_value + (1+i)*disrete_range for i in range(number_of_discrete_values)]\n",
        "        data[:, column_index] = np.digitize(data[:, column_index], discrete_boundaries, right=True)\n",
        "    data = data.astype('int32')\n",
        "    return data"
      ],
      "metadata": {
        "id": "07e_lMigH5zN"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_discrete = data_discretization(x_train, 4)\n",
        "x_test = data_discretization(x_test, 4)"
      ],
      "metadata": {
        "id": "HSAFMwJ-AAMv"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zxWsCszbI53r"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)\n",
        "\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.priors = {}\n",
        "        self.likelihoods = {}\n",
        "\n",
        "    def build_classifier(self, train_features, train_classes):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def data_discretization(data):\n",
        "        pass\n",
        "\n",
        "    def predict(self, sample):\n",
        "        pass\n",
        "\n",
        "\n",
        "class GaussianNaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.priors = {}\n",
        "        self.likelihoods = {}\n",
        "\n",
        "    def build_classifier(self, train_features, train_classes):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def normal_dist(x, mean, std):\n",
        "        pass\n",
        "\n",
        "    def predict(self, sample):\n",
        "        pass\n"
      ],
      "outputs": [],
      "execution_count": 111,
      "metadata": {
        "id": "fBh2tfQ44u5k"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}